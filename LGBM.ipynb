{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    'D:/data mining/infor project/train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"D:/data mining/infor project/test.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\n",
    "    \"D:/data mining/infor project/items.csv\",\n",
    ").set_index(\"item_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_2017.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"mean_30_2017\": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,\n",
    "        \"mean_60_2017\": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,\n",
    "        \"mean_140_2017\": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_60_2017\": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,\n",
    "        \"promo_140_2017\": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2017 = date(2017, 5, 31)\n",
    "X_l, y_l = [], []\n",
    "for i in range(6):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\lightgbm\\basic.py:1005: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.301899\tvalid_1's l2: 0.293989\n",
      "[200]\ttraining's l2: 0.298325\tvalid_1's l2: 0.292727\n",
      "[300]\ttraining's l2: 0.295884\tvalid_1's l2: 0.292343\n",
      "[400]\ttraining's l2: 0.293793\tvalid_1's l2: 0.292075\n",
      "[500]\ttraining's l2: 0.292012\tvalid_1's l2: 0.291989\n",
      "mean_7_2017: 1978514.90\n",
      "mean_14_2017: 1138683.77\n",
      "promo_0: 103431.63\n",
      "mean_3_2017: 91914.78\n",
      "day_1_2017: 88981.89\n",
      "mean_20_dow0_2017: 83401.11\n",
      "mean_4_dow0_2017: 63034.83\n",
      "mean_30_2017: 61431.87\n",
      "promo_14_2017: 28218.50\n",
      "mean_60_2017: 25992.91\n",
      "promo_7: 8841.28\n",
      "promo_60_2017: 7454.01\n",
      "mean_4_dow5_2017: 6793.31\n",
      "mean_140_2017: 6127.87\n",
      "mean_4_dow6_2017: 5793.50\n",
      "mean_20_dow4_2017: 5611.08\n",
      "promo_140_2017: 5594.21\n",
      "mean_20_dow2_2017: 4230.85\n",
      "mean_4_dow2_2017: 3870.97\n",
      "promo_9: 3452.53\n",
      "mean_20_dow3_2017: 3001.48\n",
      "mean_4_dow1_2017: 2758.68\n",
      "mean_4_dow3_2017: 2653.85\n",
      "mean_20_dow1_2017: 2613.85\n",
      "promo_14: 2413.99\n",
      "mean_4_dow4_2017: 2363.34\n",
      "mean_20_dow6_2017: 2243.62\n",
      "mean_20_dow5_2017: 1938.62\n",
      "promo_15: 1453.10\n",
      "promo_1: 1213.61\n",
      "promo_13: 1129.18\n",
      "promo_3: 987.48\n",
      "promo_4: 910.43\n",
      "promo_2: 844.94\n",
      "promo_11: 670.34\n",
      "promo_12: 404.96\n",
      "promo_10: 381.88\n",
      "promo_6: 245.21\n",
      "promo_8: 203.47\n",
      "promo_5: 172.06\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.3266\tvalid_1's l2: 0.327373\n",
      "[200]\ttraining's l2: 0.322955\tvalid_1's l2: 0.325837\n",
      "[300]\ttraining's l2: 0.3203\tvalid_1's l2: 0.32541\n",
      "[400]\ttraining's l2: 0.318027\tvalid_1's l2: 0.325267\n",
      "[500]\ttraining's l2: 0.316079\tvalid_1's l2: 0.325183\n",
      "mean_14_2017: 1382373.93\n",
      "mean_7_2017: 1132059.83\n",
      "mean_30_2017: 239550.45\n",
      "mean_20_dow1_2017: 77949.12\n",
      "promo_1: 63322.36\n",
      "mean_60_2017: 59224.70\n",
      "day_1_2017: 33518.36\n",
      "promo_14_2017: 22897.52\n",
      "mean_3_2017: 21085.04\n",
      "mean_4_dow1_2017: 17908.88\n",
      "promo_60_2017: 6426.35\n",
      "mean_20_dow2_2017: 6088.91\n",
      "mean_140_2017: 5340.56\n",
      "mean_20_dow4_2017: 5312.19\n",
      "mean_4_dow6_2017: 4506.11\n",
      "promo_0: 4503.92\n",
      "promo_140_2017: 4286.59\n",
      "mean_4_dow2_2017: 4169.33\n",
      "promo_3: 3898.09\n",
      "mean_4_dow0_2017: 3718.77\n",
      "mean_4_dow4_2017: 3289.39\n",
      "mean_20_dow0_2017: 3170.36\n",
      "mean_4_dow5_2017: 3078.90\n",
      "mean_4_dow3_2017: 2732.00\n",
      "mean_20_dow6_2017: 2673.00\n",
      "promo_4: 2666.74\n",
      "mean_20_dow5_2017: 2525.95\n",
      "mean_20_dow3_2017: 2124.89\n",
      "promo_2: 1470.51\n",
      "promo_5: 1455.57\n",
      "promo_7: 812.68\n",
      "promo_6: 753.30\n",
      "promo_14: 507.69\n",
      "promo_10: 359.34\n",
      "promo_15: 346.67\n",
      "promo_11: 345.94\n",
      "promo_13: 308.74\n",
      "promo_9: 305.25\n",
      "promo_8: 246.06\n",
      "promo_12: 153.59\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.329286\tvalid_1's l2: 0.341168\n",
      "[200]\ttraining's l2: 0.324905\tvalid_1's l2: 0.339795\n",
      "[300]\ttraining's l2: 0.322062\tvalid_1's l2: 0.339248\n",
      "[400]\ttraining's l2: 0.319651\tvalid_1's l2: 0.338902\n",
      "[500]\ttraining's l2: 0.317508\tvalid_1's l2: 0.338762\n",
      "mean_14_2017: 1855108.18\n",
      "mean_7_2017: 838895.71\n",
      "mean_20_dow2_2017: 248668.09\n",
      "mean_30_2017: 245252.16\n",
      "mean_4_dow2_2017: 205887.10\n",
      "promo_2: 98393.26\n",
      "promo_14_2017: 23872.04\n",
      "mean_60_2017: 23108.73\n",
      "mean_3_2017: 21808.05\n",
      "day_1_2017: 12758.70\n",
      "promo_140_2017: 10310.92\n",
      "promo_60_2017: 10152.11\n",
      "mean_20_dow4_2017: 7730.76\n",
      "promo_3: 6437.10\n",
      "promo_9: 6429.28\n",
      "mean_4_dow1_2017: 5175.10\n",
      "mean_4_dow0_2017: 4683.17\n",
      "mean_20_dow1_2017: 4504.57\n",
      "promo_0: 4487.79\n",
      "mean_4_dow3_2017: 4418.63\n",
      "mean_20_dow5_2017: 4382.13\n",
      "promo_4: 3334.72\n",
      "promo_5: 3307.59\n",
      "promo_7: 3200.22\n",
      "mean_4_dow4_2017: 3038.84\n",
      "mean_20_dow0_2017: 2860.68\n",
      "mean_20_dow3_2017: 2803.23\n",
      "mean_4_dow6_2017: 2705.17\n",
      "mean_20_dow6_2017: 2619.80\n",
      "mean_4_dow5_2017: 2603.12\n",
      "mean_140_2017: 2536.25\n",
      "promo_14: 1674.40\n",
      "promo_11: 1628.85\n",
      "promo_1: 1570.63\n",
      "promo_15: 1449.95\n",
      "promo_13: 849.62\n",
      "promo_10: 821.99\n",
      "promo_6: 804.38\n",
      "promo_12: 610.64\n",
      "promo_8: 467.98\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.35262\tvalid_1's l2: 0.354759\n",
      "[200]\ttraining's l2: 0.347926\tvalid_1's l2: 0.353033\n",
      "[300]\ttraining's l2: 0.344883\tvalid_1's l2: 0.352548\n",
      "[400]\ttraining's l2: 0.342409\tvalid_1's l2: 0.352473\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttraining's l2: 0.342592\tvalid_1's l2: 0.352417\n",
      "mean_14_2017: 2201180.52\n",
      "mean_7_2017: 651716.30\n",
      "mean_30_2017: 551888.52\n",
      "mean_4_dow3_2017: 270895.96\n",
      "mean_20_dow3_2017: 150905.92\n",
      "mean_60_2017: 125805.97\n",
      "promo_3: 73992.61\n",
      "mean_3_2017: 50444.97\n",
      "mean_4_dow4_2017: 23473.56\n",
      "promo_14_2017: 20025.95\n",
      "day_1_2017: 7307.23\n",
      "promo_60_2017: 7146.88\n",
      "promo_140_2017: 6769.11\n",
      "mean_140_2017: 6159.73\n",
      "promo_4: 5570.77\n",
      "promo_5: 5423.71\n",
      "mean_20_dow5_2017: 4501.05\n",
      "mean_20_dow0_2017: 4368.89\n",
      "mean_20_dow4_2017: 4155.30\n",
      "mean_4_dow2_2017: 4077.40\n",
      "promo_2: 3759.56\n",
      "promo_7: 3703.84\n",
      "mean_20_dow6_2017: 3514.86\n",
      "mean_4_dow0_2017: 3348.65\n",
      "mean_20_dow2_2017: 2958.94\n",
      "promo_0: 2789.39\n",
      "mean_4_dow6_2017: 2547.83\n",
      "promo_6: 2352.40\n",
      "mean_4_dow1_2017: 2150.42\n",
      "mean_4_dow5_2017: 2051.39\n",
      "mean_20_dow1_2017: 1995.56\n",
      "promo_1: 1512.21\n",
      "promo_14: 1255.11\n",
      "promo_9: 905.44\n",
      "promo_8: 630.00\n",
      "promo_10: 605.90\n",
      "promo_15: 469.10\n",
      "promo_13: 331.99\n",
      "promo_11: 259.81\n",
      "promo_12: 215.38\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.363186\tvalid_1's l2: 0.357752\n",
      "[200]\ttraining's l2: 0.358039\tvalid_1's l2: 0.356045\n",
      "[300]\ttraining's l2: 0.354454\tvalid_1's l2: 0.355269\n",
      "Early stopping, best iteration is:\n",
      "[322]\ttraining's l2: 0.353789\tvalid_1's l2: 0.355199\n",
      "mean_14_2017: 1333843.36\n",
      "mean_4_dow4_2017: 1150975.70\n",
      "mean_7_2017: 601489.01\n",
      "mean_30_2017: 550150.08\n",
      "mean_3_2017: 311687.77\n",
      "mean_20_dow4_2017: 282232.79\n",
      "promo_4: 73987.03\n",
      "mean_60_2017: 40453.06\n",
      "mean_4_dow3_2017: 22779.57\n",
      "promo_14_2017: 17916.70\n",
      "promo_7: 7692.66\n",
      "promo_60_2017: 7498.67\n",
      "promo_3: 7031.28\n",
      "promo_5: 6625.90\n",
      "promo_140_2017: 5738.58\n",
      "day_1_2017: 5450.11\n",
      "mean_20_dow1_2017: 4505.76\n",
      "mean_20_dow0_2017: 4323.60\n",
      "promo_0: 4300.78\n",
      "promo_6: 3885.53\n",
      "promo_2: 3822.81\n",
      "mean_20_dow2_2017: 3817.20\n",
      "mean_4_dow0_2017: 2976.81\n",
      "mean_20_dow3_2017: 2704.23\n",
      "mean_140_2017: 2650.96\n",
      "promo_1: 2357.77\n",
      "mean_20_dow6_2017: 2316.64\n",
      "mean_4_dow6_2017: 2174.26\n",
      "mean_4_dow2_2017: 2084.01\n",
      "promo_11: 2082.51\n",
      "mean_4_dow5_2017: 1975.09\n",
      "mean_20_dow5_2017: 1862.86\n",
      "mean_4_dow1_2017: 1747.82\n",
      "promo_14: 1713.58\n",
      "promo_9: 1687.00\n",
      "promo_10: 942.55\n",
      "promo_13: 742.20\n",
      "promo_15: 674.04\n",
      "promo_12: 544.45\n",
      "promo_8: 528.36\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.356024\tvalid_1's l2: 0.361304\n",
      "[200]\ttraining's l2: 0.351746\tvalid_1's l2: 0.359833\n",
      "[300]\ttraining's l2: 0.348721\tvalid_1's l2: 0.359347\n",
      "[400]\ttraining's l2: 0.346147\tvalid_1's l2: 0.359123\n",
      "Early stopping, best iteration is:\n",
      "[421]\ttraining's l2: 0.345662\tvalid_1's l2: 0.359062\n",
      "mean_14_2017: 1306752.88\n",
      "mean_30_2017: 1128507.57\n",
      "mean_7_2017: 307268.07\n",
      "mean_3_2017: 259393.22\n",
      "mean_60_2017: 176937.11\n",
      "mean_20_dow5_2017: 85131.45\n",
      "promo_5: 79845.93\n",
      "mean_4_dow5_2017: 64292.22\n",
      "promo_14_2017: 20134.62\n",
      "promo_3: 11308.52\n",
      "mean_4_dow6_2017: 10819.08\n",
      "day_1_2017: 7937.64\n",
      "promo_7: 7151.55\n",
      "promo_60_2017: 7134.23\n",
      "promo_6: 6515.29\n",
      "mean_140_2017: 6353.30\n",
      "mean_20_dow6_2017: 5452.55\n",
      "promo_140_2017: 4846.56\n",
      "mean_20_dow3_2017: 3799.33\n",
      "mean_20_dow0_2017: 3725.04\n",
      "mean_4_dow0_2017: 3662.68\n",
      "mean_4_dow2_2017: 3266.74\n",
      "mean_20_dow2_2017: 3119.22\n",
      "mean_4_dow4_2017: 2907.18\n",
      "mean_20_dow4_2017: 2880.84\n",
      "mean_4_dow1_2017: 2825.35\n",
      "mean_4_dow3_2017: 2751.24\n",
      "promo_4: 2659.06\n",
      "mean_20_dow1_2017: 2557.68\n",
      "promo_0: 2544.51\n",
      "promo_2: 2144.10\n",
      "promo_9: 1977.98\n",
      "promo_1: 1208.53\n",
      "promo_8: 1052.07\n",
      "promo_14: 1050.29\n",
      "promo_13: 1040.19\n",
      "promo_11: 931.91\n",
      "promo_10: 877.24\n",
      "promo_12: 873.34\n",
      "promo_15: 752.91\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346442\tvalid_1's l2: 0.421629\n",
      "[200]\ttraining's l2: 0.342101\tvalid_1's l2: 0.420967\n",
      "Early stopping, best iteration is:\n",
      "[214]\ttraining's l2: 0.341619\tvalid_1's l2: 0.420805\n",
      "mean_14_2017: 1271349.34\n",
      "mean_30_2017: 874078.25\n",
      "mean_7_2017: 400693.71\n",
      "mean_20_dow6_2017: 156734.65\n",
      "mean_3_2017: 142114.74\n",
      "mean_60_2017: 131148.81\n",
      "promo_6: 127292.75\n",
      "mean_4_dow6_2017: 123827.00\n",
      "promo_14_2017: 20003.70\n",
      "day_1_2017: 13405.13\n",
      "promo_3: 10908.94\n",
      "mean_20_dow5_2017: 10028.12\n",
      "promo_7: 8936.32\n",
      "promo_60_2017: 7438.08\n",
      "mean_4_dow5_2017: 7107.90\n",
      "promo_140_2017: 5026.09\n",
      "promo_5: 4530.00\n",
      "mean_20_dow1_2017: 3733.82\n",
      "promo_13: 3506.69\n",
      "mean_140_2017: 3496.18\n",
      "mean_20_dow0_2017: 3045.01\n",
      "promo_0: 2817.37\n",
      "promo_4: 2598.09\n",
      "mean_4_dow0_2017: 2510.05\n",
      "mean_20_dow3_2017: 2423.96\n",
      "mean_4_dow1_2017: 2358.21\n",
      "promo_9: 2246.30\n",
      "mean_20_dow4_2017: 2000.22\n",
      "promo_14: 1984.24\n",
      "mean_4_dow2_2017: 1905.13\n",
      "mean_20_dow2_2017: 1653.82\n",
      "promo_2: 1490.79\n",
      "mean_4_dow3_2017: 1443.81\n",
      "mean_4_dow4_2017: 1273.40\n",
      "promo_1: 1249.32\n",
      "promo_15: 1190.85\n",
      "promo_8: 732.00\n",
      "promo_11: 668.35\n",
      "promo_12: 631.69\n",
      "promo_10: 484.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.332548\tvalid_1's l2: 0.389649\n",
      "[200]\ttraining's l2: 0.328122\tvalid_1's l2: 0.388945\n",
      "[300]\ttraining's l2: 0.325173\tvalid_1's l2: 0.388443\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttraining's l2: 0.324566\tvalid_1's l2: 0.388373\n",
      "mean_30_2017: 1183731.36\n",
      "mean_14_2017: 1049243.91\n",
      "mean_7_2017: 631079.91\n",
      "promo_7: 181180.08\n",
      "mean_20_dow0_2017: 161474.08\n",
      "mean_60_2017: 100777.77\n",
      "mean_4_dow0_2017: 72262.15\n",
      "promo_0: 24062.59\n",
      "mean_3_2017: 20006.49\n",
      "day_1_2017: 19287.37\n",
      "promo_14_2017: 12761.71\n",
      "promo_60_2017: 11815.54\n",
      "promo_14: 9988.27\n",
      "promo_140_2017: 8988.26\n",
      "mean_140_2017: 7812.30\n",
      "mean_20_dow2_2017: 5697.92\n",
      "mean_20_dow4_2017: 5452.09\n",
      "promo_3: 5333.96\n",
      "promo_5: 3449.94\n",
      "promo_6: 3408.86\n",
      "mean_20_dow1_2017: 3336.79\n",
      "mean_4_dow6_2017: 2894.49\n",
      "mean_4_dow5_2017: 2886.03\n",
      "mean_20_dow3_2017: 2879.61\n",
      "promo_9: 2866.80\n",
      "mean_4_dow1_2017: 2503.73\n",
      "mean_4_dow3_2017: 2299.88\n",
      "mean_4_dow2_2017: 2184.03\n",
      "mean_20_dow5_2017: 2174.62\n",
      "promo_4: 2168.00\n",
      "mean_20_dow6_2017: 2130.07\n",
      "mean_4_dow4_2017: 1834.18\n",
      "promo_15: 1834.10\n",
      "promo_2: 1653.68\n",
      "promo_8: 1147.02\n",
      "promo_10: 1130.15\n",
      "promo_13: 1042.63\n",
      "promo_11: 845.68\n",
      "promo_1: 483.73\n",
      "promo_12: 357.43\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.342096\tvalid_1's l2: 0.380329\n",
      "[200]\ttraining's l2: 0.337948\tvalid_1's l2: 0.379344\n",
      "[300]\ttraining's l2: 0.335153\tvalid_1's l2: 0.3791\n",
      "[400]\ttraining's l2: 0.332849\tvalid_1's l2: 0.37891\n",
      "Early stopping, best iteration is:\n",
      "[369]\ttraining's l2: 0.333539\tvalid_1's l2: 0.37888\n",
      "mean_30_2017: 1120134.21\n",
      "mean_14_2017: 711687.22\n",
      "mean_7_2017: 444423.74\n",
      "mean_60_2017: 278009.58\n",
      "mean_20_dow1_2017: 112600.44\n",
      "promo_8: 103697.50\n",
      "mean_4_dow1_2017: 26459.05\n",
      "day_1_2017: 19210.75\n",
      "promo_10: 19202.24\n",
      "promo_14_2017: 16423.48\n",
      "mean_3_2017: 12165.73\n",
      "promo_60_2017: 11559.31\n",
      "mean_20_dow2_2017: 8864.70\n",
      "promo_7: 7897.16\n",
      "mean_140_2017: 5671.97\n",
      "mean_20_dow4_2017: 5575.50\n",
      "promo_140_2017: 5355.18\n",
      "promo_11: 4170.09\n",
      "promo_12: 3867.59\n",
      "mean_4_dow0_2017: 3574.58\n",
      "mean_20_dow0_2017: 3530.88\n",
      "mean_4_dow6_2017: 3359.84\n",
      "mean_4_dow2_2017: 3339.32\n",
      "promo_9: 3135.16\n",
      "mean_20_dow6_2017: 2813.84\n",
      "mean_4_dow4_2017: 2493.03\n",
      "mean_20_dow5_2017: 2444.95\n",
      "mean_4_dow5_2017: 2397.54\n",
      "mean_4_dow3_2017: 2275.72\n",
      "promo_0: 2234.14\n",
      "promo_13: 1871.98\n",
      "mean_20_dow3_2017: 1784.89\n",
      "promo_14: 1730.57\n",
      "promo_3: 1528.28\n",
      "promo_6: 1246.45\n",
      "promo_4: 1134.96\n",
      "promo_2: 632.99\n",
      "promo_5: 533.88\n",
      "promo_1: 481.63\n",
      "promo_15: 431.27\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346295\tvalid_1's l2: 0.369356\n",
      "[200]\ttraining's l2: 0.341431\tvalid_1's l2: 0.368345\n",
      "[300]\ttraining's l2: 0.338265\tvalid_1's l2: 0.367825\n",
      "[400]\ttraining's l2: 0.33569\tvalid_1's l2: 0.367532\n",
      "[500]\ttraining's l2: 0.333375\tvalid_1's l2: 0.367346\n",
      "mean_30_2017: 1072223.56\n",
      "mean_14_2017: 901806.05\n",
      "mean_7_2017: 454243.88\n",
      "mean_20_dow2_2017: 390814.75\n",
      "mean_4_dow2_2017: 319242.30\n",
      "promo_9: 127395.26\n",
      "mean_60_2017: 71035.26\n",
      "promo_14_2017: 21102.95\n",
      "promo_10: 13956.11\n",
      "promo_140_2017: 13902.69\n",
      "promo_2: 13211.98\n",
      "mean_3_2017: 11700.97\n",
      "promo_60_2017: 11229.04\n",
      "mean_20_dow4_2017: 8906.99\n",
      "promo_7: 8847.48\n",
      "day_1_2017: 7954.54\n",
      "mean_20_dow1_2017: 7445.86\n",
      "promo_8: 7421.10\n",
      "mean_4_dow1_2017: 6762.66\n",
      "promo_14: 4796.58\n",
      "mean_4_dow0_2017: 4743.83\n",
      "mean_20_dow5_2017: 4640.57\n",
      "mean_20_dow0_2017: 4299.52\n",
      "promo_11: 3978.73\n",
      "mean_4_dow3_2017: 3787.41\n",
      "promo_12: 3748.20\n",
      "mean_4_dow6_2017: 3137.45\n",
      "mean_20_dow6_2017: 3108.87\n",
      "mean_4_dow4_2017: 3049.80\n",
      "mean_20_dow3_2017: 3026.55\n",
      "mean_4_dow5_2017: 3020.15\n",
      "promo_13: 2786.11\n",
      "mean_140_2017: 2486.42\n",
      "promo_0: 1261.73\n",
      "promo_6: 1152.69\n",
      "promo_1: 961.52\n",
      "promo_4: 944.70\n",
      "promo_15: 851.90\n",
      "promo_3: 390.82\n",
      "promo_5: 281.01\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.374345\tvalid_1's l2: 0.37472\n",
      "[200]\ttraining's l2: 0.36916\tvalid_1's l2: 0.373127\n",
      "[300]\ttraining's l2: 0.365626\tvalid_1's l2: 0.372899\n",
      "Early stopping, best iteration is:\n",
      "[268]\ttraining's l2: 0.36677\tvalid_1's l2: 0.372823\n",
      "mean_30_2017: 1548663.74\n",
      "mean_14_2017: 735214.40\n",
      "mean_7_2017: 645865.79\n",
      "mean_60_2017: 374732.52\n",
      "mean_4_dow3_2017: 241793.10\n",
      "mean_20_dow3_2017: 197653.13\n",
      "promo_10: 105684.72\n",
      "mean_3_2017: 18548.91\n",
      "promo_14_2017: 15627.69\n",
      "mean_4_dow4_2017: 13738.21\n",
      "promo_60_2017: 11446.77\n",
      "mean_4_dow2_2017: 10443.97\n",
      "promo_140_2017: 6797.79\n",
      "mean_140_2017: 6621.11\n",
      "promo_14: 6201.35\n",
      "promo_9: 5841.13\n",
      "promo_7: 5731.42\n",
      "promo_12: 5292.28\n",
      "day_1_2017: 4714.30\n",
      "promo_11: 4499.99\n",
      "mean_20_dow5_2017: 4269.14\n",
      "mean_20_dow0_2017: 3891.67\n",
      "promo_13: 3887.40\n",
      "mean_20_dow2_2017: 3871.98\n",
      "mean_20_dow6_2017: 3455.22\n",
      "mean_4_dow0_2017: 3312.96\n",
      "mean_20_dow4_2017: 3109.45\n",
      "promo_8: 3032.76\n",
      "mean_20_dow1_2017: 2427.57\n",
      "promo_3: 2169.49\n",
      "mean_4_dow6_2017: 1879.36\n",
      "mean_4_dow1_2017: 1776.90\n",
      "mean_4_dow5_2017: 1560.01\n",
      "promo_0: 1501.89\n",
      "promo_6: 985.88\n",
      "promo_15: 904.83\n",
      "promo_4: 832.33\n",
      "promo_2: 577.74\n",
      "promo_1: 414.38\n",
      "promo_5: 383.40\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.384696\tvalid_1's l2: 0.386293\n",
      "[200]\ttraining's l2: 0.379015\tvalid_1's l2: 0.384726\n",
      "[300]\ttraining's l2: 0.375213\tvalid_1's l2: 0.384294\n",
      "[400]\ttraining's l2: 0.372342\tvalid_1's l2: 0.384265\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's l2: 0.373604\tvalid_1's l2: 0.384218\n",
      "mean_4_dow4_2017: 1325325.81\n",
      "mean_30_2017: 1162573.09\n",
      "mean_14_2017: 678315.05\n",
      "mean_20_dow4_2017: 277397.80\n",
      "mean_7_2017: 243529.42\n",
      "mean_60_2017: 214741.54\n",
      "mean_3_2017: 116256.61\n",
      "promo_11: 95235.32\n",
      "promo_14_2017: 17118.72\n",
      "mean_4_dow3_2017: 16391.27\n",
      "promo_12: 13445.26\n",
      "promo_14: 11737.20\n",
      "promo_10: 9214.00\n",
      "promo_140_2017: 8726.85\n",
      "promo_60_2017: 7502.66\n",
      "promo_13: 7190.08\n",
      "promo_9: 5675.25\n",
      "promo_4: 5230.81\n",
      "day_1_2017: 4907.44\n",
      "mean_20_dow0_2017: 4883.01\n",
      "mean_20_dow1_2017: 4778.03\n",
      "mean_20_dow3_2017: 4678.26\n",
      "promo_7: 4029.51\n",
      "mean_140_2017: 3824.70\n",
      "mean_20_dow2_2017: 3536.72\n",
      "promo_8: 3416.54\n",
      "mean_4_dow0_2017: 3137.53\n",
      "mean_20_dow6_2017: 3136.00\n",
      "mean_20_dow5_2017: 3111.56\n",
      "mean_4_dow2_2017: 2421.34\n",
      "mean_4_dow6_2017: 2397.07\n",
      "mean_4_dow5_2017: 2205.95\n",
      "mean_4_dow1_2017: 2148.27\n",
      "promo_0: 2068.06\n",
      "promo_15: 1465.31\n",
      "promo_6: 996.85\n",
      "promo_2: 691.84\n",
      "promo_1: 684.72\n",
      "promo_3: 575.28\n",
      "promo_5: 458.74\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.370486\tvalid_1's l2: 0.377031\n",
      "[200]\ttraining's l2: 0.36576\tvalid_1's l2: 0.376319\n",
      "[300]\ttraining's l2: 0.362421\tvalid_1's l2: 0.376084\n",
      "Early stopping, best iteration is:\n",
      "[327]\ttraining's l2: 0.361569\tvalid_1's l2: 0.376047\n",
      "mean_30_2017: 1578899.42\n",
      "mean_14_2017: 596123.66\n",
      "mean_60_2017: 395812.05\n",
      "mean_7_2017: 304157.58\n",
      "mean_3_2017: 145606.00\n",
      "promo_12: 94469.18\n",
      "mean_20_dow5_2017: 83916.71\n",
      "mean_4_dow5_2017: 72819.77\n",
      "promo_13: 20256.90\n",
      "promo_14_2017: 14918.64\n",
      "promo_14: 13473.11\n",
      "promo_10: 11268.96\n",
      "promo_60_2017: 10113.86\n",
      "mean_140_2017: 9490.20\n",
      "day_1_2017: 8651.74\n",
      "mean_20_dow0_2017: 6777.62\n",
      "promo_140_2017: 5783.39\n",
      "mean_20_dow6_2017: 4819.01\n",
      "mean_4_dow0_2017: 3904.45\n",
      "mean_20_dow3_2017: 3902.29\n",
      "mean_4_dow6_2017: 3755.47\n",
      "promo_9: 3501.93\n",
      "promo_11: 3455.67\n",
      "mean_20_dow2_2017: 3234.85\n",
      "mean_4_dow2_2017: 2515.24\n",
      "mean_4_dow3_2017: 2496.02\n",
      "promo_7: 2479.68\n",
      "promo_15: 2475.86\n",
      "mean_20_dow1_2017: 2448.46\n",
      "mean_20_dow4_2017: 2414.94\n",
      "mean_4_dow4_2017: 2386.10\n",
      "mean_4_dow1_2017: 2222.57\n",
      "promo_8: 1659.84\n",
      "promo_0: 1452.61\n",
      "promo_5: 1304.84\n",
      "promo_6: 1020.78\n",
      "promo_2: 610.47\n",
      "promo_3: 605.30\n",
      "promo_4: 451.15\n",
      "promo_1: 396.95\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.359742\tvalid_1's l2: 0.362344\n",
      "[200]\ttraining's l2: 0.355395\tvalid_1's l2: 0.361548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's l2: 0.352241\tvalid_1's l2: 0.361233\n",
      "Early stopping, best iteration is:\n",
      "[342]\ttraining's l2: 0.351064\tvalid_1's l2: 0.361192\n",
      "mean_30_2017: 1472506.43\n",
      "mean_14_2017: 432875.62\n",
      "mean_7_2017: 375627.18\n",
      "mean_60_2017: 281826.61\n",
      "mean_20_dow6_2017: 215639.24\n",
      "promo_13: 162050.25\n",
      "mean_3_2017: 90129.56\n",
      "mean_4_dow6_2017: 76470.08\n",
      "day_1_2017: 24286.43\n",
      "promo_14_2017: 16644.53\n",
      "mean_20_dow5_2017: 11921.10\n",
      "promo_14: 11022.72\n",
      "mean_4_dow5_2017: 10589.03\n",
      "promo_60_2017: 9941.11\n",
      "promo_10: 8703.56\n",
      "mean_20_dow1_2017: 8473.93\n",
      "mean_140_2017: 7294.54\n",
      "promo_140_2017: 6583.40\n",
      "promo_6: 6478.54\n",
      "mean_20_dow0_2017: 5783.16\n",
      "promo_12: 5515.47\n",
      "mean_4_dow1_2017: 3414.07\n",
      "mean_4_dow0_2017: 3203.93\n",
      "mean_20_dow3_2017: 3148.16\n",
      "promo_0: 3120.02\n",
      "mean_20_dow4_2017: 2884.00\n",
      "promo_9: 2880.91\n",
      "mean_20_dow2_2017: 2702.85\n",
      "promo_11: 2696.21\n",
      "mean_4_dow3_2017: 2443.59\n",
      "mean_4_dow4_2017: 2377.83\n",
      "promo_15: 2219.09\n",
      "mean_4_dow2_2017: 1985.44\n",
      "promo_7: 1768.63\n",
      "promo_8: 1340.60\n",
      "promo_2: 822.22\n",
      "promo_1: 567.02\n",
      "promo_4: 508.06\n",
      "promo_5: 427.57\n",
      "promo_3: 420.73\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346957\tvalid_1's l2: 0.349115\n",
      "[200]\ttraining's l2: 0.342481\tvalid_1's l2: 0.348022\n",
      "[300]\ttraining's l2: 0.339324\tvalid_1's l2: 0.347879\n",
      "Early stopping, best iteration is:\n",
      "[278]\ttraining's l2: 0.340027\tvalid_1's l2: 0.347798\n",
      "mean_30_2017: 1489648.36\n",
      "mean_14_2017: 719875.93\n",
      "mean_7_2017: 349045.02\n",
      "mean_20_dow0_2017: 287084.72\n",
      "promo_14: 196279.74\n",
      "mean_60_2017: 162177.77\n",
      "mean_4_dow0_2017: 66752.20\n",
      "promo_14_2017: 16254.20\n",
      "promo_7: 16045.02\n",
      "day_1_2017: 15978.39\n",
      "promo_0: 12635.60\n",
      "promo_60_2017: 11556.32\n",
      "promo_140_2017: 11291.91\n",
      "mean_3_2017: 10607.53\n",
      "promo_13: 9752.16\n",
      "mean_20_dow2_2017: 9259.59\n",
      "mean_140_2017: 7173.05\n",
      "promo_12: 5693.33\n",
      "mean_20_dow4_2017: 5444.75\n",
      "promo_10: 5014.56\n",
      "promo_9: 3806.98\n",
      "mean_20_dow1_2017: 3660.73\n",
      "mean_4_dow2_2017: 3574.13\n",
      "promo_15: 3510.80\n",
      "mean_20_dow3_2017: 2572.73\n",
      "mean_4_dow6_2017: 2537.55\n",
      "mean_20_dow6_2017: 2491.36\n",
      "mean_4_dow5_2017: 2202.34\n",
      "mean_4_dow1_2017: 2202.27\n",
      "mean_20_dow5_2017: 2090.90\n",
      "promo_2: 1916.96\n",
      "mean_4_dow4_2017: 1834.03\n",
      "mean_4_dow3_2017: 1604.14\n",
      "promo_11: 1563.58\n",
      "promo_6: 1492.02\n",
      "promo_4: 1002.84\n",
      "promo_8: 910.91\n",
      "promo_3: 583.90\n",
      "promo_1: 486.84\n",
      "promo_5: 378.06\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.357412\tvalid_1's l2: 0.37231\n",
      "[200]\ttraining's l2: 0.353223\tvalid_1's l2: 0.371317\n",
      "[300]\ttraining's l2: 0.350261\tvalid_1's l2: 0.370957\n",
      "Early stopping, best iteration is:\n",
      "[268]\ttraining's l2: 0.351162\tvalid_1's l2: 0.370869\n",
      "mean_30_2017: 1371554.83\n",
      "mean_14_2017: 491469.92\n",
      "mean_60_2017: 414558.05\n",
      "mean_7_2017: 212109.75\n",
      "promo_15: 132991.95\n",
      "mean_20_dow1_2017: 124494.98\n",
      "day_1_2017: 18278.09\n",
      "mean_4_dow1_2017: 17971.51\n",
      "mean_20_dow2_2017: 14327.39\n",
      "promo_14_2017: 12703.04\n",
      "promo_60_2017: 11674.88\n",
      "promo_14: 8850.17\n",
      "mean_3_2017: 8260.00\n",
      "promo_140_2017: 6634.93\n",
      "mean_140_2017: 5563.96\n",
      "mean_20_dow4_2017: 4960.73\n",
      "mean_20_dow0_2017: 3778.24\n",
      "mean_4_dow0_2017: 3237.71\n",
      "promo_10: 3070.43\n",
      "promo_13: 2533.91\n",
      "mean_4_dow6_2017: 2531.11\n",
      "mean_20_dow6_2017: 2443.60\n",
      "mean_4_dow2_2017: 2323.83\n",
      "promo_12: 2105.11\n",
      "mean_20_dow5_2017: 1977.15\n",
      "mean_4_dow5_2017: 1897.23\n",
      "mean_20_dow3_2017: 1770.86\n",
      "mean_4_dow4_2017: 1764.29\n",
      "mean_4_dow3_2017: 1694.48\n",
      "promo_7: 1524.96\n",
      "promo_0: 1485.97\n",
      "promo_9: 1372.62\n",
      "promo_11: 1151.25\n",
      "promo_8: 970.65\n",
      "promo_6: 876.46\n",
      "promo_4: 702.15\n",
      "promo_2: 651.66\n",
      "promo_1: 472.78\n",
      "promo_5: 405.92\n",
      "promo_3: 367.82\n",
      "Validation mse: 0.362440352689\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'num_leaves': 31,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 300,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 500\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 6) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=100\n",
    "    )\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('lgb.csv', float_format='%.4f', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.array(val_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_val, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-07-26\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "df_preds[\"unit_sales\"] = np.clip(np.expm1(df_preds[\"unit_sales\"]), 0, 1000)\n",
    "df_preds.reset_index().to_csv('lgb_cv.csv', float_format='%.4f', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"16\" valign=\"top\">96995</th>\n",
       "      <th>2017-07-26</th>\n",
       "      <td>0.156697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-27</th>\n",
       "      <td>0.166952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-28</th>\n",
       "      <td>0.223916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-29</th>\n",
       "      <td>0.271277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-30</th>\n",
       "      <td>0.183197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>0.152104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>0.148364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-02</th>\n",
       "      <td>0.154628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-03</th>\n",
       "      <td>0.169900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04</th>\n",
       "      <td>0.238883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-05</th>\n",
       "      <td>0.253776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-06</th>\n",
       "      <td>0.176575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-07</th>\n",
       "      <td>0.148087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-08</th>\n",
       "      <td>0.147112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-09</th>\n",
       "      <td>0.151156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-10</th>\n",
       "      <td>0.162156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">99197</th>\n",
       "      <th>2017-07-26</th>\n",
       "      <td>0.650797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-27</th>\n",
       "      <td>0.673490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-28</th>\n",
       "      <td>0.964496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-29</th>\n",
       "      <td>0.852681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-30</th>\n",
       "      <td>0.488215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>0.616755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>0.575416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-02</th>\n",
       "      <td>0.692576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-03</th>\n",
       "      <td>0.638582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04</th>\n",
       "      <td>0.969357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-05</th>\n",
       "      <td>0.830418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-06</th>\n",
       "      <td>0.613462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-07</th>\n",
       "      <td>0.637164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-08</th>\n",
       "      <td>0.557394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">54</th>\n",
       "      <th rowspan=\"14\" valign=\"top\">2113914</th>\n",
       "      <th>2017-07-28</th>\n",
       "      <td>3.797133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-29</th>\n",
       "      <td>4.882874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-30</th>\n",
       "      <td>7.786122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>4.124765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>0.474537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-02</th>\n",
       "      <td>2.588148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-03</th>\n",
       "      <td>4.123481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04</th>\n",
       "      <td>4.026056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-05</th>\n",
       "      <td>1.148477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-06</th>\n",
       "      <td>6.364554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-07</th>\n",
       "      <td>0.664888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-08</th>\n",
       "      <td>5.069025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-09</th>\n",
       "      <td>4.353873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-10</th>\n",
       "      <td>4.703055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">2116416</th>\n",
       "      <th>2017-07-26</th>\n",
       "      <td>0.009188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-27</th>\n",
       "      <td>0.006286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-29</th>\n",
       "      <td>0.035116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-30</th>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>0.023029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>0.052357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-02</th>\n",
       "      <td>0.037137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-03</th>\n",
       "      <td>0.044088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04</th>\n",
       "      <td>0.016537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-05</th>\n",
       "      <td>0.040715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-06</th>\n",
       "      <td>0.030587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-07</th>\n",
       "      <td>1.965262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-08</th>\n",
       "      <td>0.025106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-09</th>\n",
       "      <td>0.047885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-10</th>\n",
       "      <td>0.035724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2680240 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               unit_sales\n",
       "store_nbr item_nbr date                  \n",
       "1         96995    2017-07-26    0.156697\n",
       "                   2017-07-27    0.166952\n",
       "                   2017-07-28    0.223916\n",
       "                   2017-07-29    0.271277\n",
       "                   2017-07-30    0.183197\n",
       "                   2017-07-31    0.152104\n",
       "                   2017-08-01    0.148364\n",
       "                   2017-08-02    0.154628\n",
       "                   2017-08-03    0.169900\n",
       "                   2017-08-04    0.238883\n",
       "                   2017-08-05    0.253776\n",
       "                   2017-08-06    0.176575\n",
       "                   2017-08-07    0.148087\n",
       "                   2017-08-08    0.147112\n",
       "                   2017-08-09    0.151156\n",
       "                   2017-08-10    0.162156\n",
       "          99197    2017-07-26    0.650797\n",
       "                   2017-07-27    0.673490\n",
       "                   2017-07-28    0.964496\n",
       "                   2017-07-29    0.852681\n",
       "                   2017-07-30    0.488215\n",
       "                   2017-07-31    0.616755\n",
       "                   2017-08-01    0.575416\n",
       "                   2017-08-02    0.692576\n",
       "                   2017-08-03    0.638582\n",
       "                   2017-08-04    0.969357\n",
       "                   2017-08-05    0.830418\n",
       "                   2017-08-06    0.613462\n",
       "                   2017-08-07    0.637164\n",
       "                   2017-08-08    0.557394\n",
       "...                                   ...\n",
       "54        2113914  2017-07-28    3.797133\n",
       "                   2017-07-29    4.882874\n",
       "                   2017-07-30    7.786122\n",
       "                   2017-07-31    4.124765\n",
       "                   2017-08-01    0.474537\n",
       "                   2017-08-02    2.588148\n",
       "                   2017-08-03    4.123481\n",
       "                   2017-08-04    4.026056\n",
       "                   2017-08-05    1.148477\n",
       "                   2017-08-06    6.364554\n",
       "                   2017-08-07    0.664888\n",
       "                   2017-08-08    5.069025\n",
       "                   2017-08-09    4.353873\n",
       "                   2017-08-10    4.703055\n",
       "          2116416  2017-07-26    0.009188\n",
       "                   2017-07-27    0.006286\n",
       "                   2017-07-28    0.000000\n",
       "                   2017-07-29    0.035116\n",
       "                   2017-07-30    0.035558\n",
       "                   2017-07-31    0.023029\n",
       "                   2017-08-01    0.052357\n",
       "                   2017-08-02    0.037137\n",
       "                   2017-08-03    0.044088\n",
       "                   2017-08-04    0.016537\n",
       "                   2017-08-05    0.040715\n",
       "                   2017-08-06    0.030587\n",
       "                   2017-08-07    1.965262\n",
       "                   2017-08-08    0.025106\n",
       "                   2017-08-09    0.047885\n",
       "                   2017-08-10    0.035724\n",
       "\n",
       "[2680240 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day_1_2017', 'mean_140_2017', 'mean_14_2017', 'mean_30_2017',\n",
       "       'mean_3_2017', 'mean_60_2017', 'mean_7_2017', 'promo_140_2017',\n",
       "       'promo_14_2017', 'promo_60_2017', 'mean_4_dow0_2017',\n",
       "       'mean_20_dow0_2017', 'mean_4_dow1_2017', 'mean_20_dow1_2017',\n",
       "       'mean_4_dow2_2017', 'mean_20_dow2_2017', 'mean_4_dow3_2017',\n",
       "       'mean_20_dow3_2017', 'mean_4_dow4_2017', 'mean_20_dow4_2017',\n",
       "       'mean_4_dow5_2017', 'mean_20_dow5_2017', 'mean_4_dow6_2017',\n",
       "       'mean_20_dow6_2017', 'promo_0', 'promo_1', 'promo_2', 'promo_3',\n",
       "       'promo_4', 'promo_5', 'promo_6', 'promo_7', 'promo_8', 'promo_9',\n",
       "       'promo_10', 'promo_11', 'promo_12', 'promo_13', 'promo_14', 'promo_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-08-16 00:00:00</th>\n",
       "      <th>2017-08-17 00:00:00</th>\n",
       "      <th>2017-08-18 00:00:00</th>\n",
       "      <th>2017-08-19 00:00:00</th>\n",
       "      <th>2017-08-20 00:00:00</th>\n",
       "      <th>2017-08-21 00:00:00</th>\n",
       "      <th>2017-08-22 00:00:00</th>\n",
       "      <th>2017-08-23 00:00:00</th>\n",
       "      <th>2017-08-24 00:00:00</th>\n",
       "      <th>2017-08-25 00:00:00</th>\n",
       "      <th>2017-08-26 00:00:00</th>\n",
       "      <th>2017-08-27 00:00:00</th>\n",
       "      <th>2017-08-28 00:00:00</th>\n",
       "      <th>2017-08-29 00:00:00</th>\n",
       "      <th>2017-08-30 00:00:00</th>\n",
       "      <th>2017-08-31 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-08-16  2017-08-17  2017-08-18  2017-08-19  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103501         False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "\n",
       "date                2017-08-20  2017-08-21  2017-08-22  2017-08-23  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103501         False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "\n",
       "date                2017-08-24  2017-08-25  2017-08-26  2017-08-27  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103501         False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "\n",
       "date                2017-08-28  2017-08-29  2017-08-30  2017-08-31  \n",
       "store_nbr item_nbr                                                  \n",
       "1         96995          False       False       False       False  \n",
       "          99197          False       False       False       False  \n",
       "          103501         False       False       False       False  \n",
       "          103520         False       False       False       False  \n",
       "          103665         False       False       False       False  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
